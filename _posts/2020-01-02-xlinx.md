---
title: Extract links/images from files or URLs
type: post
tags: [ perl, Mojolicious, web, client, link, image ]
comment: true
date: 2020-01-02 00:29:45
---

**TL;DR**

> if you need to squeeze all link/image URLs from HTML files or URLs, 
> look no further. Quick'n'dirty but should serve most needs.

<script src="https://gitlab.com/polettix/notechs/snippets/1926435.js"></script>

This is a quick'n'dirty way of extracting all links (i.e. `href` attributes of `a` tags) and images (i.e. `src` attributes of `img` tags) out of a list of local files (interpreted as HTML) or URLs (dynamically downloaded). Leverages [Mojolicious][].

It's very bare-bones, e.g. it does not pre-pend a *base URL* in case of relative URLs. It should be a good starting point though.

> This post mirrors [this snippet][snippet] on [GitLab][]. All changes will happen
> there; in case of need, here's a locally cached version:

```perl
#!/usr/bin/env perl
use strict;
use warnings;
use feature 'say';
use Mojo::DOM;
use Mojo::File;
use Mojo::UserAgent;
my $ua = Mojo::UserAgent->new;
for my $input (@ARGV) {
    my $dom = $input =~ m{\A https?:// }imxs
        ? $ua->get($input)->result->dom
        : Mojo::DOM->new(Mojo::File->new($input)->slurp);
    $dom->find('a[href],img[src]')->each(
        sub { say $_[0]->attr(lc($_[0]->tag) eq 'a' ? 'href' : 'src') }
    );
}
```

[Mojolicious]: https://metacpan.org/release/Mojolicious
[snippet]: https://gitlab.com/polettix/notechs/snippets/1926435
[GitLab]: https://gitlab.com/
